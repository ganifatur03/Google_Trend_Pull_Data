{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c0e932",
   "metadata": {},
   "source": [
    "## This file is used to format raw data for All Historical Google Trends data for Power BI Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df4cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6365319",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_folder = \"D:/Data work/Lenovo/Raw Data/Backup/04. Share of Search/04. Share of Search (13 May - with yearly data for 2024 and 2025)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da63da4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading sheet 'CAP9' from D:/Data work/Lenovo/Raw Data/Backup/04. Share of Search/04. Share of Search (13 May - with yearly data for 2024 and 2025)\\01.2024-04.2024\\~$01.2024-04.2024.xlsx: File is not a zip file\n",
      "Error loading sheet 'JP' from D:/Data work/Lenovo/Raw Data/Backup/04. Share of Search/04. Share of Search (13 May - with yearly data for 2024 and 2025)\\01.2024-04.2024\\~$01.2024-04.2024.xlsx: File is not a zip file\n",
      "Error loading sheet 'IN' from D:/Data work/Lenovo/Raw Data/Backup/04. Share of Search/04. Share of Search (13 May - with yearly data for 2024 and 2025)\\01.2024-04.2024\\~$01.2024-04.2024.xlsx: File is not a zip file\n",
      "Error loading sheet 'ANZ' from D:/Data work/Lenovo/Raw Data/Backup/04. Share of Search/04. Share of Search (13 May - with yearly data for 2024 and 2025)\\01.2024-04.2024\\~$01.2024-04.2024.xlsx: File is not a zip file\n",
      "Error loading sheet 'CAP9' from D:/Data work/Lenovo/Raw Data/Backup/04. Share of Search/04. Share of Search (13 May - with yearly data for 2024 and 2025)\\02.2019-12.2023\\~$2019-2013.xlsx: File is not a zip file\n",
      "Error loading sheet 'JP' from D:/Data work/Lenovo/Raw Data/Backup/04. Share of Search/04. Share of Search (13 May - with yearly data for 2024 and 2025)\\02.2019-12.2023\\~$2019-2013.xlsx: File is not a zip file\n",
      "Error loading sheet 'IN' from D:/Data work/Lenovo/Raw Data/Backup/04. Share of Search/04. Share of Search (13 May - with yearly data for 2024 and 2025)\\02.2019-12.2023\\~$2019-2013.xlsx: File is not a zip file\n",
      "Error loading sheet 'ANZ' from D:/Data work/Lenovo/Raw Data/Backup/04. Share of Search/04. Share of Search (13 May - with yearly data for 2024 and 2025)\\02.2019-12.2023\\~$2019-2013.xlsx: File is not a zip file\n",
      "Combined shape: (135005, 8)\n"
     ]
    }
   ],
   "source": [
    "# Cari semua file Excel di dalam subfolder\n",
    "excel_files = glob(os.path.join(sos_folder, \"*\", \"*.xlsx\"))\n",
    "\n",
    "# List untuk simpan semua DataFrame\n",
    "all_dataframes = []\n",
    "\n",
    "# Sheet names to read\n",
    "sheet_names = [\"CAP9\", \"JP\", \"IN\", \"ANZ\"]\n",
    "\n",
    "# Loop through all files and read into DataFrames\n",
    "for file in excel_files:\n",
    "    try:\n",
    "        # Read each sheet in the file\n",
    "        for sheet in sheet_names:\n",
    "            try:\n",
    "                df = pd.read_excel(file, sheet_name=sheet, engine=\"openpyxl\")\n",
    "                df['source_file'] = os.path.basename(file)  # Add filename\n",
    "                df['source_folder'] = os.path.basename(os.path.dirname(file))  # Add folder name\n",
    "                df['sheet_name'] = sheet  # Add sheet name for reference\n",
    "                all_dataframes.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading sheet '{sheet}' from {file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Combine all DataFrames if any were loaded\n",
    "if all_dataframes:\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    print(f\"Combined shape: {combined_df.shape}\")\n",
    "else:\n",
    "    print(\"No data was loaded. Check the path and file patterns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4fb7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Week",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Search term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Trend index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_folder",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sheet_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "64a34a3b-90aa-4f86-a950-6e907f2f9f17",
       "rows": [
        [
         "0",
         "2024-01-01 00:00:00",
         "Indonesia",
         "CAP",
         "IDEAPAD",
         "77.28571428571429",
         "01.2024-04.2024.xlsx",
         "01.2024-04.2024",
         "CAP9"
        ],
        [
         "1",
         "2024-01-08 00:00:00",
         "Indonesia",
         "CAP",
         "IDEAPAD",
         "72.42857142857143",
         "01.2024-04.2024.xlsx",
         "01.2024-04.2024",
         "CAP9"
        ],
        [
         "2",
         "2024-01-15 00:00:00",
         "Indonesia",
         "CAP",
         "IDEAPAD",
         "80.71428571428571",
         "01.2024-04.2024.xlsx",
         "01.2024-04.2024",
         "CAP9"
        ],
        [
         "3",
         "2024-01-22 00:00:00",
         "Indonesia",
         "CAP",
         "IDEAPAD",
         "87.71428571428571",
         "01.2024-04.2024.xlsx",
         "01.2024-04.2024",
         "CAP9"
        ],
        [
         "4",
         "2024-01-29 00:00:00",
         "Indonesia",
         "CAP",
         "IDEAPAD",
         "72.66666666666667",
         "01.2024-04.2024.xlsx",
         "01.2024-04.2024",
         "CAP9"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Search term</th>\n",
       "      <th>Trend index</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_folder</th>\n",
       "      <th>sheet_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>CAP</td>\n",
       "      <td>IDEAPAD</td>\n",
       "      <td>77.285714</td>\n",
       "      <td>01.2024-04.2024.xlsx</td>\n",
       "      <td>01.2024-04.2024</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>CAP</td>\n",
       "      <td>IDEAPAD</td>\n",
       "      <td>72.428571</td>\n",
       "      <td>01.2024-04.2024.xlsx</td>\n",
       "      <td>01.2024-04.2024</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>CAP</td>\n",
       "      <td>IDEAPAD</td>\n",
       "      <td>80.714286</td>\n",
       "      <td>01.2024-04.2024.xlsx</td>\n",
       "      <td>01.2024-04.2024</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>CAP</td>\n",
       "      <td>IDEAPAD</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>01.2024-04.2024.xlsx</td>\n",
       "      <td>01.2024-04.2024</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>CAP</td>\n",
       "      <td>IDEAPAD</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>01.2024-04.2024.xlsx</td>\n",
       "      <td>01.2024-04.2024</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Week    Country Region Search term  Trend index           source_file  \\\n",
       "0 2024-01-01  Indonesia    CAP     IDEAPAD    77.285714  01.2024-04.2024.xlsx   \n",
       "1 2024-01-08  Indonesia    CAP     IDEAPAD    72.428571  01.2024-04.2024.xlsx   \n",
       "2 2024-01-15  Indonesia    CAP     IDEAPAD    80.714286  01.2024-04.2024.xlsx   \n",
       "3 2024-01-22  Indonesia    CAP     IDEAPAD    87.714286  01.2024-04.2024.xlsx   \n",
       "4 2024-01-29  Indonesia    CAP     IDEAPAD    72.666667  01.2024-04.2024.xlsx   \n",
       "\n",
       "     source_folder sheet_name  \n",
       "0  01.2024-04.2024       CAP9  \n",
       "1  01.2024-04.2024       CAP9  \n",
       "2  01.2024-04.2024       CAP9  \n",
       "3  01.2024-04.2024       CAP9  \n",
       "4  01.2024-04.2024       CAP9  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69585f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"sos_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61830c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_share_of_search_data(t_df):\n",
    "    month_dict = {\n",
    "        1: 'January',\n",
    "        2: 'February',\n",
    "        3: 'March',\n",
    "        4: 'April',\n",
    "        5: 'May',\n",
    "        6: 'June',\n",
    "        7: 'July',\n",
    "        8: 'August',\n",
    "        9: 'September',\n",
    "        10: 'October',\n",
    "        11: 'November',\n",
    "        12: 'December'\n",
    "    }\n",
    "    t_df['Year'] = t_df['Week'].dt.year\n",
    "    t_df['Month.no'] = t_df['Week'].dt.month\n",
    "    t_df['Month Name'] = t_df['Month.no'].map(month_dict)\n",
    "    t_df['Quarter'] = 'Q' + t_df['Week'].dt.quarter.astype(str)\n",
    "    t_df['MMM'] = t_df['Month Name'].str[:3]\n",
    "    t_df['Quarter (SOS)'] = t_df['Quarter'] + ' FY' + t_df['Year'].astype(str)\n",
    "    search_rename = {\n",
    "        'LENOVO IDEAPAD': 'IDEAPAD',\n",
    "        'LENOVO LEGION': 'LEGION',\n",
    "        'LENOVO YOGA': 'YOGA',\n",
    "        'LENOVO LOQ': 'LOQ',\n",
    "        'LENOVO TABLET': 'TABLET',\n",
    "        'LENOVO TAB': 'TAB',\n",
    "        'ACER INSPIRE': 'ACER ASPIRE',  # Correcting typo\n",
    "        'APLLE IPAD': 'APPLE IPAD'  # Correcting typo\n",
    "    }\n",
    "\n",
    "    t_df['Search term'] = t_df['Search term'].replace(search_rename)\n",
    "\n",
    "    search_mapping = {\n",
    "        'ACER ASPIRE': {'premium&gaming':np.nan, 'brand': 'ACER', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'ACER NITRO': {'premium&gaming':'Mainstream Gaming', 'brand': 'ACER', 'lenovo&competitor': 'LOQ'},\n",
    "        'ACER PREDATOR': {'premium&gaming':'Gaming', 'brand': 'ACER', 'lenovo&competitor': 'LEGION'},\n",
    "        'ACER SWIFT': {'premium&gaming':'Premium', 'brand': 'ACER', 'lenovo&competitor': 'YOGA'},\n",
    "        'APPLE IPAD': {'premium&gaming':np.nan, 'brand': 'APPLE', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'APPLE MACBOOK': {'premium&gaming':'Premium', 'brand': 'APPLE', 'lenovo&competitor': 'YOGA'},\n",
    "        'ASUS ROG': {'premium&gaming':'Gaming', 'brand': 'ASUS', 'lenovo&competitor': 'LEGION'},\n",
    "        'ASUS TUF': {'premium&gaming':'Mainstream Gaming', 'brand': 'ASUS', 'lenovo&competitor': 'LOQ'},\n",
    "        'ASUS VIVOBOOK': {'premium&gaming':np.nan, 'brand': 'ASUS', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'ASUS ZENBOOK': {'premium&gaming':'Premium', 'brand': 'ASUS', 'lenovo&competitor': 'YOGA'},\n",
    "        'DELL INSPIRON': {'premium&gaming':np.nan, 'brand': 'DELL', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'DELL INSPIRON 7000': {'premium&gaming':'Premium', 'brand': 'DELL', 'lenovo&competitor': 'YOGA'},\n",
    "        'DELL XPS': {'premium&gaming':'Premium', 'brand': 'DELL', 'lenovo&competitor': 'YOGA'},\n",
    "        'HP ENVY': {'premium&gaming':'Premium', 'brand': 'HP', 'lenovo&competitor': 'YOGA'},\n",
    "        'HP OMEN': {'premium&gaming':'Gaming', 'brand': 'HP', 'lenovo&competitor': 'LEGION'},\n",
    "        'HP PAVILION': {'premium&gaming':np.nan, 'brand': 'HP', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'HP SPECTRE': {'premium&gaming':'Premium', 'brand': 'HP', 'lenovo&competitor': 'YOGA'},\n",
    "        'HP VICTUS': {'premium&gaming':'Mainstream Gaming', 'brand': 'HP', 'lenovo&competitor': 'LOQ'},\n",
    "        'HUAWEI MATEBOOK': {'premium&gaming':np.nan, 'brand': 'HUAWEI', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'HUAWEI MATEPAD': {'premium&gaming':np.nan, 'brand': 'HUAWEI', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'IDEAPAD': {'premium&gaming':np.nan, 'brand': 'LENOVO', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'LEGION': {'premium&gaming':'Gaming', 'brand': 'LENOVO', 'lenovo&competitor': 'LEGION'},\n",
    "        'LENOVO': {'premium&gaming':np.nan, 'brand': 'LENOVO', 'lenovo&competitor': 'LENOVO'},\n",
    "        'LOQ': {'premium&gaming':'Mainstream Gaming', 'brand': 'LENOVO', 'lenovo&competitor': 'LOQ'},\n",
    "        'MSI CYBORG': {'premium&gaming':'Mainstream Gaming', 'brand': 'MSI', 'lenovo&competitor': 'LOQ'},\n",
    "        'MSI GAMING': {'premium&gaming':'Gaming', 'brand': 'MSI', 'lenovo&competitor': 'LEGION'},\n",
    "        'NEC LAVIE': {'premium&gaming':'Premium', 'brand': 'NEC', 'lenovo&competitor': 'YOGA'},\n",
    "        'REALME PAD': {'premium&gaming':np.nan, 'brand': 'REALME', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'SAMSUNG GALAXY TAB': {'premium&gaming':np.nan, 'brand': 'SAMSUNG', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'TAB': {'premium&gaming':np.nan, 'brand': 'LENOVO', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'TABLET': {'premium&gaming':np.nan, 'brand': 'LENOVO', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'XIAOMI PAD': {'premium&gaming':np.nan, 'brand': 'XIAOMI', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'YOGA': {'premium&gaming':'Premium', 'brand': 'LENOVO', 'lenovo&competitor': 'YOGA'}\n",
    "    }\n",
    "    # Map premium&gaming\n",
    "    t_df['Premium & Gaming'] = t_df['Search term'].map(lambda x: search_mapping.get(x, {}).get('premium&gaming'))\n",
    "\n",
    "    # Map brand\n",
    "    t_df['Brand'] = t_df['Search term'].map(lambda x: search_mapping.get(x, {}).get('brand'))\n",
    "\n",
    "    # Map lenovo&competitor\n",
    "    t_df['Lenovo & Competitor'] = t_df['Search term'].map(lambda x: search_mapping.get(x, {}).get('lenovo&competitor'))\n",
    "\n",
    "    country_mapping = {\n",
    "        'INDONESIA': 'Indonesia',\n",
    "        'MALAYSIA': 'Malaysia',\n",
    "        'SINGAPORE': 'Singapore',\n",
    "        'PHILIPPINES': 'Philippines',\n",
    "        'VIETNAM': 'Vietnam',\n",
    "        'THAILAND': 'Thailand',\n",
    "        'TAIWAN': 'Taiwan',\n",
    "        'HONG KONG': 'Hong Kong',\n",
    "        'SOUTH KOREA': 'South Korea'\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    # Apply the mapping to standardize country names\n",
    "    t_df['Country'] = t_df['Country'].replace(country_mapping)\n",
    "\n",
    "    t_df['Merge'] = t_df['Quarter (SOS)'] + ' ' + t_df['Country'] + ' ' + t_df['Search term']\n",
    "    t_df = t_df[['Week', 'Country', 'Region', 'Search term', 'Trend index', 'Brand',\n",
    "        'Premium & Gaming', 'Year', 'Month Name', 'Month.no', 'Quarter', 'MMM',\n",
    "        'Quarter (SOS)', 'Merge', 'Lenovo & Competitor']]\n",
    "    \n",
    "    return t_df\n",
    "\n",
    "t_df = clean_share_of_search_data(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59891f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135005, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de031cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df.to_csv(\"sos_processed_yearly.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
