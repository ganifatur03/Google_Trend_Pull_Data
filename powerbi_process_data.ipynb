{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c0e932",
   "metadata": {},
   "source": [
    "## This file is used to format raw data for All Historical Google Trends data for Power BI Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6df4cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6365319",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_folder = \"D:/Data work/Lenovo/Raw Data/04. Share of Search (new)/All Category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da63da4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (72276, 8)\n"
     ]
    }
   ],
   "source": [
    "# Cari semua file Excel di dalam subfolder\n",
    "excel_files = glob(os.path.join(sos_folder, \"*\", \"*.xlsx\"))\n",
    "\n",
    "# List untuk simpan semua DataFrame\n",
    "all_dataframes = []\n",
    "\n",
    "# Sheet names to read\n",
    "sheet_names = [\"CAP9\", \"JP\", \"IN\", \"ANZ\"]\n",
    "\n",
    "# Loop through all files and read into DataFrames\n",
    "for file in excel_files:\n",
    "    try:\n",
    "        # Read each sheet in the file\n",
    "        for sheet in sheet_names:\n",
    "            try:\n",
    "                df = pd.read_excel(file, sheet_name=sheet, engine=\"openpyxl\")\n",
    "                df['source_file'] = os.path.basename(file)  # Add filename\n",
    "                df['source_folder'] = os.path.basename(os.path.dirname(file))  # Add folder name\n",
    "                df['sheet_name'] = sheet  # Add sheet name for reference\n",
    "                all_dataframes.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading sheet '{sheet}' from {file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Combine all DataFrames if any were loaded\n",
    "if all_dataframes:\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    print(f\"Combined shape: {combined_df.shape}\")\n",
    "else:\n",
    "    print(\"No data was loaded. Check the path and file patterns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd4fb7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Week",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Search term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Trend index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_folder",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sheet_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5ebd5cf0-9ec4-4e39-a792-0736e354a10b",
       "rows": [
        [
         "0",
         "2021-12-26 00:00:00",
         "INDONESIA",
         "CAP",
         "LENOVO",
         "72",
         "Brand-2225-all - Processed.xlsx",
         "5 Jun 2025",
         "CAP9"
        ],
        [
         "1",
         "2022-01-02 00:00:00",
         "INDONESIA",
         "CAP",
         "LENOVO",
         "95",
         "Brand-2225-all - Processed.xlsx",
         "5 Jun 2025",
         "CAP9"
        ],
        [
         "2",
         "2022-01-09 00:00:00",
         "INDONESIA",
         "CAP",
         "LENOVO",
         "100",
         "Brand-2225-all - Processed.xlsx",
         "5 Jun 2025",
         "CAP9"
        ],
        [
         "3",
         "2022-01-16 00:00:00",
         "INDONESIA",
         "CAP",
         "LENOVO",
         "96",
         "Brand-2225-all - Processed.xlsx",
         "5 Jun 2025",
         "CAP9"
        ],
        [
         "4",
         "2022-01-23 00:00:00",
         "INDONESIA",
         "CAP",
         "LENOVO",
         "95",
         "Brand-2225-all - Processed.xlsx",
         "5 Jun 2025",
         "CAP9"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Search term</th>\n",
       "      <th>Trend index</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_folder</th>\n",
       "      <th>sheet_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>CAP</td>\n",
       "      <td>LENOVO</td>\n",
       "      <td>72</td>\n",
       "      <td>Brand-2225-all - Processed.xlsx</td>\n",
       "      <td>5 Jun 2025</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>CAP</td>\n",
       "      <td>LENOVO</td>\n",
       "      <td>95</td>\n",
       "      <td>Brand-2225-all - Processed.xlsx</td>\n",
       "      <td>5 Jun 2025</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>CAP</td>\n",
       "      <td>LENOVO</td>\n",
       "      <td>100</td>\n",
       "      <td>Brand-2225-all - Processed.xlsx</td>\n",
       "      <td>5 Jun 2025</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>CAP</td>\n",
       "      <td>LENOVO</td>\n",
       "      <td>96</td>\n",
       "      <td>Brand-2225-all - Processed.xlsx</td>\n",
       "      <td>5 Jun 2025</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>CAP</td>\n",
       "      <td>LENOVO</td>\n",
       "      <td>95</td>\n",
       "      <td>Brand-2225-all - Processed.xlsx</td>\n",
       "      <td>5 Jun 2025</td>\n",
       "      <td>CAP9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Week    Country Region Search term  Trend index  \\\n",
       "0 2021-12-26  INDONESIA    CAP      LENOVO           72   \n",
       "1 2022-01-02  INDONESIA    CAP      LENOVO           95   \n",
       "2 2022-01-09  INDONESIA    CAP      LENOVO          100   \n",
       "3 2022-01-16  INDONESIA    CAP      LENOVO           96   \n",
       "4 2022-01-23  INDONESIA    CAP      LENOVO           95   \n",
       "\n",
       "                       source_file source_folder sheet_name  \n",
       "0  Brand-2225-all - Processed.xlsx    5 Jun 2025       CAP9  \n",
       "1  Brand-2225-all - Processed.xlsx    5 Jun 2025       CAP9  \n",
       "2  Brand-2225-all - Processed.xlsx    5 Jun 2025       CAP9  \n",
       "3  Brand-2225-all - Processed.xlsx    5 Jun 2025       CAP9  \n",
       "4  Brand-2225-all - Processed.xlsx    5 Jun 2025       CAP9  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69585f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"sos_output_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61830c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_share_of_search_data(t_df):\n",
    "    month_dict = {\n",
    "        1: 'January',\n",
    "        2: 'February',\n",
    "        3: 'March',\n",
    "        4: 'April',\n",
    "        5: 'May',\n",
    "        6: 'June',\n",
    "        7: 'July',\n",
    "        8: 'August',\n",
    "        9: 'September',\n",
    "        10: 'October',\n",
    "        11: 'November',\n",
    "        12: 'December'\n",
    "    }\n",
    "    t_df['Year'] = t_df['Week'].dt.year\n",
    "    t_df['Month.no'] = t_df['Week'].dt.month\n",
    "    t_df['Month Name'] = t_df['Month.no'].map(month_dict)\n",
    "    t_df['Quarter'] = 'Q' + t_df['Week'].dt.quarter.astype(str)\n",
    "    t_df['MMM'] = t_df['Month Name'].str[:3]\n",
    "    t_df['Quarter (SOS)'] = t_df['Quarter'] + ' FY' + t_df['Year'].astype(str)\n",
    "    search_rename = {\n",
    "        'LENOVO IDEAPAD': 'IDEAPAD',\n",
    "        'LENOVO LEGION': 'LEGION',\n",
    "        'LENOVO YOGA': 'YOGA',\n",
    "        'LENOVO LOQ': 'LOQ',\n",
    "        'LENOVO TABLET': 'TABLET',\n",
    "        'LENOVO TAB': 'TAB',\n",
    "        'ACER INSPIRE': 'ACER ASPIRE',  # Correcting typo\n",
    "        'APLLE IPAD': 'APPLE IPAD'  # Correcting typo\n",
    "    }\n",
    "\n",
    "    t_df['Search term'] = t_df['Search term'].replace(search_rename)\n",
    "\n",
    "    search_mapping = {\n",
    "        'ACER ASPIRE': {'premium&gaming':np.nan, 'brand': 'ACER', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'ACER NITRO': {'premium&gaming':'Mainstream Gaming', 'brand': 'ACER', 'lenovo&competitor': 'LOQ'},\n",
    "        'ACER PREDATOR': {'premium&gaming':'Gaming', 'brand': 'ACER', 'lenovo&competitor': 'LEGION'},\n",
    "        'ACER SWIFT': {'premium&gaming':'Premium', 'brand': 'ACER', 'lenovo&competitor': 'YOGA'},\n",
    "        'APPLE IPAD': {'premium&gaming':np.nan, 'brand': 'APPLE', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'APPLE MACBOOK': {'premium&gaming':'Premium', 'brand': 'APPLE', 'lenovo&competitor': 'YOGA'},\n",
    "        'ASUS ROG': {'premium&gaming':'Gaming', 'brand': 'ASUS', 'lenovo&competitor': 'LEGION'},\n",
    "        'ASUS TUF': {'premium&gaming':'Mainstream Gaming', 'brand': 'ASUS', 'lenovo&competitor': 'LOQ'},\n",
    "        'ASUS VIVOBOOK': {'premium&gaming':np.nan, 'brand': 'ASUS', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'ASUS ZENBOOK': {'premium&gaming':'Premium', 'brand': 'ASUS', 'lenovo&competitor': 'YOGA'},\n",
    "        'DELL INSPIRON': {'premium&gaming':np.nan, 'brand': 'DELL', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'DELL INSPIRON 7000': {'premium&gaming':'Premium', 'brand': 'DELL', 'lenovo&competitor': 'YOGA'},\n",
    "        'DELL XPS': {'premium&gaming':'Premium', 'brand': 'DELL', 'lenovo&competitor': 'YOGA'},\n",
    "        'HP ENVY': {'premium&gaming':'Premium', 'brand': 'HP', 'lenovo&competitor': 'YOGA'},\n",
    "        'HP OMEN': {'premium&gaming':'Gaming', 'brand': 'HP', 'lenovo&competitor': 'LEGION'},\n",
    "        'HP PAVILION': {'premium&gaming':np.nan, 'brand': 'HP', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'HP SPECTRE': {'premium&gaming':'Premium', 'brand': 'HP', 'lenovo&competitor': 'YOGA'},\n",
    "        'HP VICTUS': {'premium&gaming':'Mainstream Gaming', 'brand': 'HP', 'lenovo&competitor': 'LOQ'},\n",
    "        'HUAWEI MATEBOOK': {'premium&gaming':np.nan, 'brand': 'HUAWEI', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'HUAWEI MATEPAD': {'premium&gaming':np.nan, 'brand': 'HUAWEI', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'IDEAPAD': {'premium&gaming':np.nan, 'brand': 'LENOVO', 'lenovo&competitor': 'IDEAPAD'},\n",
    "        'LEGION': {'premium&gaming':'Gaming', 'brand': 'LENOVO', 'lenovo&competitor': 'LEGION'},\n",
    "        'LENOVO': {'premium&gaming':np.nan, 'brand': 'LENOVO', 'lenovo&competitor': 'LENOVO'},\n",
    "        'LOQ': {'premium&gaming':'Mainstream Gaming', 'brand': 'LENOVO', 'lenovo&competitor': 'LOQ'},\n",
    "        'MSI CYBORG': {'premium&gaming':'Mainstream Gaming', 'brand': 'MSI', 'lenovo&competitor': 'LOQ'},\n",
    "        'MSI GAMING': {'premium&gaming':'Gaming', 'brand': 'MSI', 'lenovo&competitor': 'LEGION'},\n",
    "        'NEC LAVIE': {'premium&gaming':'Premium', 'brand': 'NEC', 'lenovo&competitor': 'YOGA'},\n",
    "        'REALME PAD': {'premium&gaming':np.nan, 'brand': 'REALME', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'SAMSUNG GALAXY TAB': {'premium&gaming':np.nan, 'brand': 'SAMSUNG', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'TAB': {'premium&gaming':np.nan, 'brand': 'LENOVO', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'TABLET': {'premium&gaming':np.nan, 'brand': 'LENOVO', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'XIAOMI PAD': {'premium&gaming':np.nan, 'brand': 'XIAOMI', 'lenovo&competitor': 'TAB/TABLET'},\n",
    "        'YOGA': {'premium&gaming':'Premium', 'brand': 'LENOVO', 'lenovo&competitor': 'YOGA'}\n",
    "    }\n",
    "    # Map premium&gaming\n",
    "    t_df['Premium & Gaming'] = t_df['Search term'].map(lambda x: search_mapping.get(x, {}).get('premium&gaming'))\n",
    "\n",
    "    # Map brand\n",
    "    t_df['Brand'] = t_df['Search term'].map(lambda x: search_mapping.get(x, {}).get('brand'))\n",
    "\n",
    "    # Map lenovo&competitor\n",
    "    t_df['Lenovo & Competitor'] = t_df['Search term'].map(lambda x: search_mapping.get(x, {}).get('lenovo&competitor'))\n",
    "\n",
    "    country_mapping = {\n",
    "        'INDONESIA': 'Indonesia',\n",
    "        'MALAYSIA': 'Malaysia',\n",
    "        'SINGAPORE': 'Singapore',\n",
    "        'PHILIPPINES': 'Philippines',\n",
    "        'VIETNAM': 'Vietnam',\n",
    "        'THAILAND': 'Thailand',\n",
    "        'TAIWAN': 'Taiwan',\n",
    "        'HONG KONG': 'Hong Kong',\n",
    "        'SOUTH KOREA': 'South Korea',\n",
    "        'JAPAN': 'Japan',\n",
    "        'INDIA' : 'India',\n",
    "        'AUSTRALIA': 'Australia',\n",
    "        'NEW ZEALAND': 'New Zealand',\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    # Apply the mapping to standardize country names\n",
    "    t_df['Country'] = t_df['Country'].replace(country_mapping)\n",
    "    t_df['Week'] = t_df['Week'].dt.date\n",
    "\n",
    "    t_df['Merge'] = t_df['Quarter (SOS)'] + ' ' + t_df['Country'] + ' ' + t_df['Search term']\n",
    "    t_df = t_df[['Week', 'Country', 'Region', 'Search term', 'Trend index', 'Brand',\n",
    "        'Premium & Gaming', 'Year', 'Month Name', 'Month.no', 'Quarter', 'MMM',\n",
    "        'Quarter (SOS)', 'Merge', 'Lenovo & Competitor']]\n",
    "    \n",
    "    return t_df\n",
    "\n",
    "t_df = clean_share_of_search_data(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59891f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72276, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de031cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df.to_csv(\"sos_processed_yearly.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
